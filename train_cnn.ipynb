{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rock-Paper-Scissors\n",
    "Training a CNN on rock-paper-scissors hand images to build a simple game application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define paths\n",
    "train_folder = 'dataset/train'\n",
    "test_folder = 'dataset/test'\n",
    "validation_folder = 'dataset/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open test picture\n",
    "def load_image(img_path: str) -> np.ndarray:\n",
    "    image = cv2.imread(img_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image_rgb\n",
    "\n",
    "def display_image(image: np.ndarray) -> None:\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "rock_folder = 'dataset/train/rock'\n",
    "test_image = random.choice(os.listdir(rock_folder))\n",
    "image_path = os.path.join(rock_folder, test_image)\n",
    "img = load_image(image_path)\n",
    "display_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_img = image_gen.random_transform(img)\n",
    "display_image(random_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen.flow_from_directory(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen.flow_from_directory(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image shape Tensor\n",
    "image_shape = (300, 300, 3)\n",
    "\n",
    "# create sequential modle\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=image_shape))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "\n",
    "# Add 50% dropout to help reduce overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=3, activation='softmax'))  # 3 classes: 0=rock, 1=paper 2=scissors\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving the model to GPU\n",
    "WIP, I currently cannot see my GPU listed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_image_gen = image_gen.flow_from_directory(\n",
    "    directory=train_folder,\n",
    "    target_size=image_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_gen = image_gen.flow_from_directory(\n",
    "    directory=test_folder,\n",
    "    target_size=image_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices\n",
    "class_indices = train_image_gen.class_indices\n",
    "class_labels = {v:k for k, v in class_indices.items()}\n",
    "print(class_indices)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    train_image_gen,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=train_image_gen.samples/train_image_gen.batch_size,\n",
    "    validation_data=test_image_gen,\n",
    "    validation_steps=test_image_gen.samples/test_image_gen.batch_size,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "model.save(f'models/rps_v05_100epochs_{timestamp}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/rps_v04_100epochs_20240209_2137.h5')\n",
    "class_indices = {'paper': 0, 'rock': 1, 'scissors': 2}\n",
    "class_labels = {v:k for k, v in class_indices.items()}\n",
    "\n",
    "img_size = 300, 300\n",
    "img_file = r'test\\scissors.png'\n",
    "img = image.load_img(img_file, target_size=img_size)\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img/255\n",
    "\n",
    "prediction_prob = model.predict(img, verbose=0)\n",
    "print(prediction_prob)\n",
    "predicted_class_index = np.argmax(prediction_prob)\n",
    "print(predicted_class_index)\n",
    "predicted_class_prob = prediction_prob[0][predicted_class_index]\n",
    "print(predicted_class_prob)\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "print(predicted_class_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation folder prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = 0\n",
    "failure = 0\n",
    "total = 0\n",
    "failed_images = []\n",
    "\n",
    "# load model\n",
    "model = load_model('models/rps_v04_100epochs_20240209_2137.h5')\n",
    "class_indices = {'paper': 0, 'rock': 1, 'scissors': 2}\n",
    "class_labels = {v:k for k, v in class_indices.items()}\n",
    "\n",
    "for subfolder in ['rock', 'paper', 'scissors']:\n",
    "\n",
    "    current_folder = os.path.join(validation_folder, subfolder)\n",
    "\n",
    "    for img_name in os.listdir(current_folder):\n",
    "\n",
    "        img_file = os.path.normpath(os.path.join(current_folder, img_name))\n",
    "\n",
    "        img = image.load_img(img_file, target_size=(150, 150))\n",
    "        img_array = image.img_to_array(img)\n",
    "\n",
    "        # add batch dimension\n",
    "        img_normalized = img_array/255\n",
    "        img_expanded = np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "        # image prediction probability\n",
    "        prediction_prob = model.predict(img_expanded, verbose=0)\n",
    "        # print(prediction_prob)\n",
    "\n",
    "        # Get predicted class index\n",
    "        predicted_class_index = np.argmax(prediction_prob)\n",
    "\n",
    "        # Map predicted class index to class label\n",
    "        predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "        # Print predicted class label\n",
    "        if subfolder == predicted_class_label:\n",
    "            success += 1\n",
    "            result = 'success'\n",
    "        else:\n",
    "            failure += 1\n",
    "            result = 'failure'\n",
    "            failed_images.append((img_normalized, predicted_class_label, img_file))\n",
    "\n",
    "        total += 1\n",
    "        print(f'\\rImages Classified: {total} | Success: {success} | Failure: {failure} | Accuracy: {success/total*100:.2f}%', end=' ', flush=True)\n",
    "\n",
    "# print failed images with prediction and path\n",
    "if failed_images:\n",
    "    print(f\"\\n{50 * '-'}\\nFAILED IMAGES:\")\n",
    "    for img, label, path in failed_images:\n",
    "        print(path)\n",
    "        img_size = 200\n",
    "        plt.figure(figsize=(img_size/100, img_size/100))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(label, loc='left')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/rps_v04_100epochs_20240209_2137.h5')\n",
    "class_labels = {0: 'paper', 1: 'rock', 2: 'scissors'}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cv2.namedWindow('Rock Paper Scissors')\n",
    "\n",
    "img_size = 300, 300\n",
    "x, y, w, h = 895, 78, 300, 300\n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "        # copy and resize roi\n",
    "        roi_copy = cv2.resize(roi, img_size)\n",
    "        img = image.img_to_array(roi_copy)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = img / 255.0\n",
    "        prediction_prob = model.predict(img, verbose=0)\n",
    "        predicted_class_index = np.argmax(prediction_prob)\n",
    "        predicted_class_label = class_labels[predicted_class_index]\n",
    "        predicted_class_prob = prediction_prob[0][predicted_class_index]\n",
    "\n",
    "        frame[0:img_size[0], 0:img_size[1]] = roi_copy\n",
    "\n",
    "        # Display prediction\n",
    "        if predicted_class_prob < 0.9:\n",
    "            label = 'None'\n",
    "        else:\n",
    "            label = f'{predicted_class_label} ({predicted_class_prob:.2f})'\n",
    "\n",
    "        position = x, y + h + 20\n",
    "        cv2.putText(frame, label, position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Display frame\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "        cv2.imshow('Rock Paper Scissors', frame)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
