{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset Structure\n",
    "Move all images from different datasets folder in a dataset structure with test, train and validation subfolders according to a given ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Datasets -------------------------------------------------------------\n",
    "'''\n",
    "[d1]\n",
    "    [rock]\n",
    "        image1, image2, ..., imageN\n",
    "    [paper]\n",
    "        image1, image2, ..., imageN\n",
    "    [scissors]\n",
    "        image1, image2, ..., imageN\n",
    "\n",
    "[d2]\n",
    "    [rock]\n",
    "        image1, image2, ..., imageN\n",
    "    [paper]\n",
    "        image1, image2, ..., imageN\n",
    "    [scissors]\n",
    "        image1, image2, ..., imageN\n",
    "'''\n",
    "\n",
    "# Target Structure ------------------------------------------------------------\n",
    "'''\n",
    "[train]\n",
    "    [rock]\n",
    "        image1, image2, ..., imageN\n",
    "    [paper]\n",
    "        image1, image2, ..., imageN\n",
    "    [scissors]\n",
    "        image1, image2, ..., imageN\n",
    "\n",
    "[test]\n",
    "    [rock]\n",
    "        image1, image2, ..., imageN\n",
    "    [paper]\n",
    "        image1, image2, ..., imageN\n",
    "    [scissors]\n",
    "        image1, image2, ..., imageN\n",
    "\n",
    "[validation]\n",
    "    [rock]\n",
    "        image1, image2, ..., imageN\n",
    "    [paper]\n",
    "        image1, image2, ..., imageN\n",
    "    [scissors]\n",
    "        image1, image2, ..., imageN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "root_path = 'dataset'\n",
    "dataset_paths = ['d1', 'd2', 'd3']\n",
    "classes = ['rock', 'paper', 'scissors']\n",
    "steps = ['train', 'test', 'validation']\n",
    "split_ratio = [0.6, 0.2, 0.2]  # relative split ratio to dispatch train, test and validation images\n",
    "img_ext = ['jpg', 'jpeg', 'png']\n",
    "\n",
    "# define ids to be used in the new dataset img names, to avoid overwriting\n",
    "train_id = 0\n",
    "test_id = 0\n",
    "validation_id = 0\n",
    "img_count = 0\n",
    "\n",
    "try:\n",
    "    # build structure\n",
    "    for s in steps:\n",
    "        for c in classes:\n",
    "            os.makedirs(os.path.join(root_path, s, c))\n",
    "\n",
    "    # copy files\n",
    "    for d in dataset_paths:\n",
    "\n",
    "        for c in classes:\n",
    "\n",
    "            # list imaged in directory\n",
    "            source_dir = os.path.join(root_path, d, c)\n",
    "            img_list = [img for img in os.listdir(source_dir) if img.split('.')[-1].lower() in img_ext]\n",
    "            img_len = len(img_list)\n",
    "\n",
    "            # create 3 random lists of images for train, test and validation based on split ration\n",
    "            train_img_len = int(img_len * split_ratio[0])\n",
    "            train_img_list = random.sample(img_list, train_img_len)\n",
    "            test_img_len = int(img_len * split_ratio[1])\n",
    "            test_img_list = random.sample([_ for _ in img_list if _ not in train_img_list], test_img_len)\n",
    "            validation_img_list = [_ for _ in img_list if _ not in train_img_list and _ not in test_img_list]\n",
    "\n",
    "            # copy train images\n",
    "            train_target_dir = os.path.join(root_path, 'train', c)\n",
    "            for img in train_img_list:\n",
    "                source_filepath = os.path.join(source_dir, img)\n",
    "                ext = img.split('.')[-1]\n",
    "                target_filepath = os.path.join(train_target_dir, f'{c}_{d}_train_{train_id}.{ext}')\n",
    "                shutil.copy(source_filepath, target_filepath)\n",
    "                print(f'{source_filepath} -> {target_filepath}')\n",
    "                train_id += 1\n",
    "                img_count += 1\n",
    "\n",
    "            # copy test images\n",
    "            test_target_dir = os.path.join(root_path, 'test', c)\n",
    "            for img in test_img_list:\n",
    "                source_filepath = os.path.join(source_dir, img)\n",
    "                ext = img.split('.')[-1]\n",
    "                target_filepath = os.path.join(test_target_dir, f'{c}_{d}_test_{test_id}.{ext}')\n",
    "                shutil.copy(source_filepath, target_filepath)\n",
    "                print(f'{source_filepath} -> {target_filepath}')\n",
    "                test_id += 1\n",
    "                img_count += 1\n",
    "\n",
    "            # copy validation images\n",
    "            validation_target_dir = os.path.join(root_path, 'validation', c)\n",
    "            for img in validation_img_list:\n",
    "                source_filepath = os.path.join(source_dir, img)\n",
    "                ext = img.split('.')[-1]\n",
    "                target_filepath = os.path.join(validation_target_dir, f'{c}_{d}_validation_{validation_id}.{ext}')\n",
    "                shutil.copy(source_filepath, target_filepath)\n",
    "                print(f'{source_filepath} -> {target_filepath}')\n",
    "                validation_id += 1\n",
    "                img_count += 1\n",
    "\n",
    "except Exception as e:\n",
    "    print('Error creating dataset structure: ', e)\n",
    "\n",
    "print(f'Done! {img_count} copied successfully.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
