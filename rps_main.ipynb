{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 150, 100, 3), found shape=(None, 300, 300, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 231\u001b[0m\n\u001b[0;32m    229\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    230\u001b[0m img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m--> 231\u001b[0m prediction_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m predicted_class_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction_prob)\n\u001b[0;32m    233\u001b[0m predicted_class_label \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m class_indices\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m predicted_class_index][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\ALEXAN~1.DJ\\AppData\\Local\\Temp\\__autograph_generated_file1r786jqb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\alexandre.dj\\AppData\\Local\\anaconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 150, 100, 3), found shape=(None, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "## This is the main notebook to capture new images and test the model ##\n",
    "########################################################################\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#--- SETTINGS --------------------------------------------------------------------------------------\n",
    "# ROI BGR COLORS\n",
    "ROI_DEFAULT = (0, 255, 0)\n",
    "ROI_SELECTION = (0, 200, 0)\n",
    "ROI_CAPTURING = (0, 0, 255)\n",
    "ROI_SAVING = (255, 255, 255)\n",
    "ROI_PLAYING = (255, 0, 0)\n",
    "ROI_BACKGROUND = (200, 200, 200)\n",
    "ROI_CLASSIFYING = (255, 255, 255)\n",
    "\n",
    "# CAPTURE WINDOW\n",
    "window_name = \"Rock-Paper-Scissors\"\n",
    "capture_width = 1280\n",
    "capture_height = 720\n",
    "\n",
    "# ROI\n",
    "default_roi_dim = 10, 10, 300, 300  # x, y, w, h\n",
    "settings_path = \"settings.txt\"  # store some settings to file for next settion, None to disable\n",
    "\n",
    "# CAPTURE SETTINGS\n",
    "# image will be saved as \"{folder}/{img_prefix}{img_next_id}.{img_extension}\", example: captured/image_17.png.\n",
    "folder = \"captured\"\n",
    "img_prefix = \"rock_\"\n",
    "img_extension = \"png\"\n",
    "img_next_id = 0  # Starting id for image naming. If existing, the next highest id in the folder will be assigned\n",
    "frames_batch = 5  # how many frames to capture in once session\n",
    "capture_delay = 2000  # time in milliseconds to wait between captures\n",
    "\n",
    "# PLAY SETTINGS\n",
    "default_threshold = 20  # threshold to isolate hand from background in ROI\n",
    "use_threshold = True  # can be toggled with 't' key\n",
    "model = load_model('models/rps_v03_100epochs_20240208_1512.h5')\n",
    "class_indices = {'paper': 0, 'rock': 1, 'scissors': 2}\n",
    "\n",
    "# LOG SETTINGS\n",
    "log_color = (255, 255, 255)  # White color in BGR\n",
    "log_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "log_scale = 0.5\n",
    "log_thickness = 1\n",
    "show_help = False\n",
    "show_log = True\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open webcam\")\n",
    "    exit()\n",
    "\n",
    "# Define capture window\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, capture_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, capture_height)\n",
    "cv2.namedWindow(window_name)\n",
    "\n",
    "# Load settings from file or use default values\n",
    "try:\n",
    "    # Load ROI dimensions from file or use default\n",
    "    with open(settings_path, \"r\") as f:\n",
    "        x, y, w, h, threshold_amount = map(int, f.readline().split())\n",
    "        # reinit ROI if out of bounds\n",
    "        if x < 0 or y < 0 or w < 0 or h < 0 or x + w > capture_width or y + h > capture_height:\n",
    "            raise ValueError\n",
    "\n",
    "except FileNotFoundError or ValueError:\n",
    "    # use default values\n",
    "    x, y, w, h = default_roi_dim\n",
    "    threshold_amount = default_threshold\n",
    "\n",
    "# ROI init settings\n",
    "is_moving_roi = False\n",
    "mode = \"Default\"\n",
    "start_x, start_y = 0, 0\n",
    "square_color = ROI_DEFAULT\n",
    "\n",
    "# Capture init settings\n",
    "is_capturing = False\n",
    "time_counter = datetime.now()\n",
    "image_counter = 0\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Play init settings\n",
    "is_playing = False\n",
    "roi_background = None\n",
    "classify_image = False\n",
    "predicted_class_label = None\n",
    "\n",
    "# Mouse event callback function\n",
    "def mouse_callback(event, mouseX, mouseY, flags, param):\n",
    "    global x, y, w, h, is_moving_roi, start_x, start_y, square_color\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Check if mouse click is inside ROI\n",
    "        if x <= mouseX <= x + w and y <= mouseY <= y + h:\n",
    "            is_moving_roi = True\n",
    "            start_x, start_y = mouseX - x, mouseY - y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if is_moving_roi:\n",
    "            # Update ROI position while dragging\n",
    "            x = max(0, min(mouseX - start_x, frame.shape[1] - w))\n",
    "            y = max(0, min(mouseY - start_y, frame.shape[0] - h))\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        is_moving_roi = False\n",
    "\n",
    "cv2.setMouseCallback(window_name, mouse_callback)\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is read correctly\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the ROI\n",
    "    roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "    # Check for key press events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('c') and not is_playing:\n",
    "        # toogle capturing mode\n",
    "        if is_capturing:\n",
    "            is_capturing = False\n",
    "            mode = \"Default\"\n",
    "        else:\n",
    "            is_capturing = True\n",
    "            mode = \"Capturing\"\n",
    "            image_counter = 0\n",
    "    elif key == ord('p') and not is_capturing:\n",
    "        # toogle playing mode\n",
    "        if is_playing:\n",
    "            is_playing = False\n",
    "            mode = \"Default\"\n",
    "        else:\n",
    "            is_playing = True\n",
    "            mode = \"Playing\"\n",
    "            roi_background = roi.copy()\n",
    "    elif key == 32 and is_playing:\n",
    "        # Space key, capture and classify current ROI\n",
    "        classify_image = True\n",
    "    elif key == 27:\n",
    "        # Escape key, exit all modes\n",
    "        is_capturing = False\n",
    "        is_playing = False\n",
    "        is_moving_roi = False\n",
    "    elif key == ord('t'):\n",
    "        # toogle activate use threshold\n",
    "        use_threshold = not use_threshold\n",
    "    elif key == ord('+') and threshold_amount < 255:\n",
    "        # increase threshold\n",
    "        threshold_amount += 1\n",
    "    elif key == ord('-') and threshold_amount > 0:\n",
    "        # decrease threshold\n",
    "        threshold_amount -= 1\n",
    "    elif key == ord('l'):\n",
    "        # toggle log\n",
    "        show_log = not show_log\n",
    "    elif key == ord('h'):\n",
    "        # toggle help\n",
    "        show_help = not show_help\n",
    "    elif key == ord('q'):\n",
    "        # Quit the program\n",
    "        break\n",
    "\n",
    "    # Capturing Mode -------------------------------------------------------------------------------\n",
    "    if is_capturing:\n",
    "        if image_counter < frames_batch:\n",
    "            if datetime.now() - time_counter > timedelta(milliseconds=capture_delay):\n",
    "                # assign valid image id and name\n",
    "                image_ids = [int(img.replace(img_prefix, \"\").replace(f\".{img_extension}\", \"\")) for img in os.listdir(folder)\n",
    "                             if img.startswith(img_prefix) and img.endswith(f\".{img_extension}\")]\n",
    "                if img_next_id in image_ids:\n",
    "                    # assign next id\n",
    "                    img_next_id = max(image_ids) + 1\n",
    "                filepath = os.path.join(folder, f\"{img_prefix}{img_next_id}.{img_extension}\")\n",
    "                # Save the ROI image\n",
    "                cv2.imwrite(filepath, roi)\n",
    "                image_counter += 1\n",
    "                time_counter = datetime.now()\n",
    "                square_color = ROI_SAVING\n",
    "            else:\n",
    "                square_color = ROI_CAPTURING\n",
    "        elif image_counter == frames_batch:\n",
    "            # reinit counter for next capture\n",
    "            is_capturing = False\n",
    "            image_counter = 0\n",
    "\n",
    "    # Playing Mode ---------------------------------------------------------------------------------\n",
    "    elif is_playing:\n",
    "        square_color = ROI_PLAYING\n",
    "        roi_copy = roi.copy()\n",
    "\n",
    "        if use_threshold:\n",
    "            # Compare ROI and background image, any identical pixels will be white\n",
    "            diff = cv2.absdiff(roi, roi_background)\n",
    "            mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "            _, mask = cv2.threshold(mask, threshold_amount, 255, cv2.THRESH_BINARY)\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "            new_bkg = np.ones_like(roi) * ROI_BACKGROUND\n",
    "            frame[y:y+h, x:x+w] = np.where(mask==255, roi, new_bkg)\n",
    "            roi_copy = frame[y:y+h, x:x+w]\n",
    "\n",
    "        if classify_image:\n",
    "            square_color = ROI_CLASSIFYING\n",
    "            # Classify the current ROI\n",
    "            img = image.img_to_array(roi_copy)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            img = img / 255.0\n",
    "            prediction_prob = model.predict(img, verbose=0)\n",
    "            predicted_class_index = np.argmax(prediction_prob)\n",
    "            predicted_class_label = [k for k, v in class_indices.items() if v == predicted_class_index][0]\n",
    "\n",
    "    # Moving ROI -----------------------------------------------------------------------------------\n",
    "    elif is_moving_roi:\n",
    "        square_color = ROI_SELECTION\n",
    "\n",
    "    # Default Mode ---------------------------------------------------------------------------------\n",
    "    else:\n",
    "        square_color = ROI_DEFAULT\n",
    "\n",
    "    # Draw square around the ROI\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), square_color, 2)\n",
    "\n",
    "    # Show the predicted class label below ROI\n",
    "    if predicted_class_label:\n",
    "        position = x, y + h + 20\n",
    "        cv2.putText(frame, predicted_class_label, position, log_font, log_scale, ROI_PLAYING, log_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # Show help at the top left\n",
    "    if show_help:\n",
    "        text = ['LMB: Move ROI', 'C: Toggle Capture Frames', 'P: Toggle Play Mode', 'T: Toggle Threshold Use', '+/-: Adjust Threshold Amount', 'L: Toggle Log', 'H: Toggle Help', 'ESC: Exit current mode', 'Q: Quit the program']\n",
    "        y = 20\n",
    "        for line in text:\n",
    "            position = 10, y\n",
    "            cv2.putText(frame, line, position, log_font, log_scale, log_color, log_thickness, cv2.LINE_AA)\n",
    "            y += 20\n",
    "        position = 10, 10\n",
    "\n",
    "    # Show log at the bottom left\n",
    "    if show_log:\n",
    "        text = f\"ROI: {x}, {y}, {x+w}, {y+h} | Mode: {mode} | Threshold: {'On' if use_threshold else 'Off'} / {threshold_amount} | Press 'H' to toggle help\"\n",
    "        position = 10, frame.shape[0] - 10\n",
    "        cv2.putText(frame, text, position, log_font, log_scale, log_color, log_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(window_name, frame)\n",
    "\n",
    "# Save settings\n",
    "if settings_path:\n",
    "    try:\n",
    "        with open(settings_path, \"w\") as f:\n",
    "            f.write(f\"{x} {y} {w} {h} {threshold_amount}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to save settings to file: {e}\")\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
